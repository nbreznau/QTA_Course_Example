---
title: "Quanteda course"
output:
  html_document:
    df_print: paged
---



## User Notes

This is a Data Preparation Notebook for the Quanteda course organized from Sep 30 to Oct 2. 

### Goals:


A. *To identify all Drucksachen that relate to social policy* (redistribution, basic provisions, housing, pensions, health care, unemployment, active labor market policies, etc) from 1980-present. However, in this example we use only the 9th Bundestag. We are trying to first apply a dictionary and a negative-dictionary to the titles of the Drucksachen. 

B. *To analyze the content of each social policy Drucksachen* to learn:

  B.1. what policies are identified - what changed? what direction?
  B.2. What is the direction of the discussion (positive, negative, neutral)
  B.3. How does this discussion differ by parties/politicians


### Instructions for this code:

1. Create a folder called Bundestag Drucksachen in your preferred working directory

2. Change the value of lwd (below)

3. In the Bundestag Drucksachen folder, extract xml files from the zip file to a subfolder called drs09 (1980-1983). 

4. Make sure you also have the following files in the BD folder: dict.txt, negdict.txt

5. Start running the chunks below.


## Extract data from zip files

### Load libraries and initial setups


```{r lib, message = FALSE}
rm(list=ls())

library(pacman)

pacman::p_load("quanteda", "XML", "xml2")

#Paste function, save for later

pf = function(x)
{
  paste0("drs09/",x)
}

```

### Create a file list and an empty data frame for the 9th Bundestag

```{r import, message = FALSE}

drslist09 <- list.files("drs09/", pattern = ".xml")

df09 <- data.frame(text = as.character(),
                        date = as.character(),
                        voting_period = numeric(),
                        title = as.character(),
                        type = as.character(),
                        id = as.character(),
                        stringsAsFactors = FALSE)
# 
```

### Now read the files and put them all into a big dataframe. 


```{r message = FALSE}
 
for (i in drslist09){
  df09[i,1] <- xml_text(xml_find_all(read_xml(pf(i)), "//TEXT"))
  df09[i,2] <- xml_text(xml_find_all(read_xml(pf(i)), "//DATUM"))
  df09[i,3] <- xml_text(xml_find_all(read_xml(pf(i)), "//WAHLPERIODE"))
  df09[i,4] <- xml_text(xml_find_all(read_xml(pf(i)), "//TITEL"))
  df09[i,5] <- xml_text(xml_find_all(read_xml(pf(i)), "//DOKUMENTART"))
  df09[i,6] <- xml_text(xml_find_all(read_xml(pf(i)), "//NR"))
}
colnames(df09) <- c("text", "date","election period","title","document type","id")



```

### From here, start working with Quanteda. Our approach: treat titles as texts. Then use a dictionary and an anti-dictionary to identify documents that are relevant to 

```{r quanteda, message = FALSE}
## Convert to corpus

corpusDrs09 <- corpus(df09, text_field = "text", docid_field = "id" )

## Create a title-as-texts corpus

corpusDrs09_title <- corpusDrs09
texts(corpusDrs09_title) <- docvars(corpusDrs09, "title")



```

## CREATE DICTIONARY

Search all text within the Drucksachen for any word in the dictionary.
Removed the word "Arbeit", "Pflege" and 450/500 Euro jobs words.
Our list of keywords is in the file dict.txt. 
Our list of words to ignore is in the file negdict.txt


```{r dict, message = FALSE}
options(encoding = "UTF-8") # Run this to make sure the German language is read properly.

keywords <- readLines(con = "dict.txt", encoding="utf-8") #read from a txt file with all keywords.
wordlist <- as.list(setNames(keywords,keywords))
sp_dict <- dictionary(wordlist)


# Create a negative dictionary ('stopwords') to skip. Words that have social policy words in them but do not relate to social policy

keywords1 <- readLines(con = "negdict.txt", encoding="utf-8")

stopwords <- as.list(setNames(keywords1,keywords1))

sp_negdict <- dictionary(stopwords)

```


## IDENTIFY SOCIAL POLICY WORDS


### Apply Dictionary

```{r identify, echo = T, message = F, warning = F}
# Create a dataframe that indicates word matches in titles

drs09df_title <- dfm(corpusDrs09_title, dictionary = sp_dict, remove = stopwords)

# Top 40 most common terms in titles (with stopwords)

drs09dftop_title <- topfeatures(drs09df_title, n = 40)
drs09dftopt <- names(drs09dftop_title)

print(drs09dftopt)

```


### Now extract relevant documents and convert back to data frame 

```{r }
## Tokenize 
dfm_drs09_title <- tokens(corpusDrs09_title) %>%
  dfm(tolower = TRUE, 
      stem = FALSE,
      remove_punct = TRUE) %>% 
  dfm_select(pattern = sp_dict) %>%
  dfm_select(pattern = sp_negdict, selection = "remove", valuetype = "fixed")


## Convert to data frame and eliminate rows where all columns have value = 0. 

dfm_drs09_title <- convert(dfm_drs09_title, "data.frame")
dfm_drs09_title <- dfm_drs09_title[!(rowSums(dfm_drs09_title[,-1]) == 0),]

## Retrieve documents' ids 

newids <- dfm_drs09_title$doc_id

df09_new <- df09[which(df09$id %in% newids),]

## Create new Corpus with only relevant documents

corp_drs09 <- quanteda::corpus(df09_new, text_field = "text", docid_field = "id" )

```

### Pensions

```{r rente}

# tokenize

tok_drs09 <- tokens(corp_drs09)

docvars(corp_drs09)

# reduce to documents with "rentenversicherung"

corp_drs09_rente <- corpus_subset(corp_drs09, grepl("Rente", docvars(corp_drs09, "title"), fixed = T))

tok_drs09 <- corp_drs09 %>%
  tokens()

tok_drs09_rente <- corp_drs09_rente %>%
  tokens()



```

# contains an increase reference

```{r}
# This gives us an object that has the word hoehung in context.

rvschg <- kwic(tok_drs09_rente, pattern = "*höhung*", window = 6, case_insensitive = T)

View(rvschg)

dfm_drs09_rente <- tokens(corp_drs09_rente, remove_symbols = T, remove_number = T, remove_punct = T) %>%
  tokens_remove(stopwords("de")) %>% 
  dfm() %>%
  dfm_remove(c("abs","a","h","v","b","dm","nr","i"), valuetype = "fixed")




tok_drs09_rente_h <- tokens_keep(tok_drs09_rente, pattern = "*höhung*", valuetype = "glob", padding = T)


dfm_drs09_rente_h <- tok_drs09_rente_h %>% 
  tokens(remove_symbols = T, remove_number = T, remove_punct = T) %>%
  tokens_remove(stopwords("de")) %>% 
  dfm() %>%
  dfm_remove(c("abs","a","h","v","b","dm","nr","i"), valuetype = "fixed")

# alternative to cutting documents using tokens

tok_drs09_rente_h <- tokens_subset(tok_drs09_rente_h, ntoken(tok_drs09_rente_h) > 0)

topfeatures(dfm_drs09_rente, n = 30)
topfeatures(dfm_drs09_rente_h, n = 30)

# every document that mentions Rente mentions erhoehung

```

